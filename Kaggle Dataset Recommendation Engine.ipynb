{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1={\"metadata\":'''Context Machine Learning with R by Brett Lantz is a book that provides an introduction to machine learning using R. As far as I can tell, Packt Publishing does not make its datasets available online unless you buy the book and create a user account which can be a problem if you are checking the book out from the library or borrowing the book from a friend. All of these datasets are in the public domain but simply needed some cleaning up and recoding to match the format in the book.\n",
    "\n",
    "age: age of primary beneficiary\n",
    "\n",
    "sex: insurance contractor gender, female, male\n",
    "\n",
    "bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
    "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "\n",
    "children: Number of children covered by health insurance / Number of dependents\n",
    "\n",
    "smoker: Smoking\n",
    "\n",
    "region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
    "\n",
    "charges: Individual medical costs billed by health insurance''',\"name\":\"Medical Cost Personal Datasets\",\"url\":\"https://www.kaggle.com/mirichoi0218/insurance\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': \"Context Machine Learning with R by Brett Lantz is a book that provides an introduction to machine learning using R. As far as I can tell, Packt Publishing does not make its datasets available online unless you buy the book and create a user account which can be a problem if you are checking the book out from the library or borrowing the book from a friend. All of these datasets are in the public domain but simply needed some cleaning up and recoding to match the format in the book.\\n\\nage: age of primary beneficiary\\n\\nsex: insurance contractor gender, female, male\\n\\nbmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\\nobjective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\\n\\nchildren: Number of children covered by health insurance / Number of dependents\\n\\nsmoker: Smoking\\n\\nregion: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\\n\\ncharges: Individual medical costs billed by health insurance\", 'name': 'Medical Cost Personal Datasets', 'url': 'https://www.kaggle.com/mirichoi0218/insurance'}\n"
     ]
    }
   ],
   "source": [
    "print (dataset_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2={\"metadata\":'''McCarran International Airport in Las Vegas is one of the busiest airpots in the United States. It was built in 1942 and is expanding continuously since then. It has employed various innovative technologies over the year.\n",
    "\n",
    "As part of its latest innitiative, it is planning to minimize the waiting time and improve the effective usage of its runways. The obstruction to achieve this is uncertain arrivals of flights.''',\"name\":\"Airport Dataset\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3={\"metadata\":'''An Institute of Management Studies was established a few years ago. The first batch of management students has graduated and the placement season is just over. The Placement Committee wants to analyze the placements of this batch in order to improve the placements for subsequent batches. The Committe wants to check if any of the following factors play a role in deciding whether a candidate gets placed or not. It also wants to check if any of these features have any impact on the salaries.\n",
    "\n",
    "Factors:\n",
    "1. Percentages of various Levels/Exams such as 10th, 12th, Degree, MBA and Entrance Test\n",
    "2. Streams, Technologies, Specialisations chosen at various levels\n",
    "3. Previous work experience\n",
    "4. Gender\n",
    "The purpose of this notebook is to analyze the placement data of 215 candidates based on various factors and comment on the relationships and signficance of these factors.\n",
    "### Dataset Attributes:\n",
    "\n",
    "1. *sl_no*: Serial Number\n",
    "2. *gender*: Gender (M or F)\n",
    "3. *ssc_p*: 10th Grade Percentage\n",
    "4. *ssc_b*: Board of Education in 10th (Central/Others)\n",
    "5. *hsc_p*: 12th Grade Percentage\n",
    "6. *hsc_b*: Board of Education in 12th (Central/Others) \n",
    "7. *hsc_s*: Specialisation in 12th (Commerce/Science/Arts)\n",
    "8. *degree_p*: Percentage in UG\n",
    "9. *degree_t*: UG field of Education (Comm&Mgmt/Sci&Tech/Others)\n",
    "10. *workex*: Yes or No\n",
    "11. *etest_p*: Employability Test Precentage\n",
    "12. *specialisation*: MBA Field of Specialisation (Mkt&HR/Mkt&Fin)\n",
    "13. *mba_p*: Percentage in MBA\n",
    "14. *status*: Placement status (Place/Not Placed)\n",
    "15. *salary*: Salary offered in INR/Annum''',\"name\":\"placement_data\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_4 = {\"metadata\":'''We have a dataset of students in a university. The dataset has following columns:\n",
    "    1. stud.id\n",
    "    2. name\n",
    "    3. gender\n",
    "    4. age\n",
    "    5. height\n",
    "    6. weight\n",
    "    7. religion\n",
    "    8. nc.score\n",
    "    9. semester\n",
    "    10. major\n",
    "    11. minor\n",
    "    12. score1\n",
    "    13. score2\n",
    "    14. online.tutorial\n",
    "    15. graduated\n",
    "    16. salary''',\"name\":\"university_data\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_5={\"metadata\":'''*__Airbnb__* is an American online vacation-place rental company. It offers services such as lodging, homestays and other tourism services. It has become very popular in recent times due to its cheaper rental options.\n",
    "\n",
    "A Travel Agent assists customers to book rooms on Airbnb with a small commission. The agent has to constatntly keep track of the availability of rooms and recommend appropriate options to customers.\n",
    "\n",
    "Let us see how the avaialbility of rooms in different cities can be analyzed using *Probability*.''',\"name\":\"airbnb\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_6={\"metadata\":'''Kerala is one of the worst flood-hit states in India. In August 2020, the state was hit by floods that resulted due to heavy rainfall and caused damage of hundreds of crore rupees. Every year, the state experiences casualty and damages upto some extent due to heavy rainfall.\n",
    "\n",
    "Data of monthly rainfall in Kerala from 1901 to 2018 is provided. It also contains information of floods. Use this information to calculate upto what extent the heavy rainfall is responsible for floods in Kerala.### Attributes in the Dataset:\n",
    "\n",
    "__YEAR__: Year between 1901 to 2018\n",
    "\n",
    "__JAN, FEB,..., DEC__:Rainfall in mm in the specified month\n",
    "\n",
    "__ANNUAL RAINFALL__: Total rainfall in mm in that year\n",
    "\n",
    "__FLOODS__: YES or NO, in that year''',\"name\":\"kerala_floods\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_7={\"metadata\":'''Dataset from Davide Chicco, Giuseppe Jurman: â€œMachine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone. BMC Medical Informatics and Decision Making 20, 16 (2020)\n",
    "\n",
    "The columns in this dataset:\n",
    "    1. age\n",
    "    2. anaemia\n",
    "    3. creatinine_phosphokinase\n",
    "    4. diabetes\n",
    "    5. ejection_fraction\n",
    "    6. high_blood_pressure\n",
    "    7. platelets\n",
    "    8. serum_creatinine\n",
    "    9. serum_sodium\n",
    "    10. sex\n",
    "    11. smoking\n",
    "    12. time\t\n",
    "    13. DEATH_EVENT''',\"name\":\"heart_survival\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_8={\"metadata\":'''The original dataset contains 1000 entries with 20 categorial/symbolic attributes prepared by Prof. Hofmann. In this dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes.An analyst wants to analyze the data provided to know the customers to whom the bank gives credit. He does analysis on the data to gain the insights of the customers.\n",
    "    1. Age (numeric)\n",
    "    2. Sex (text: male, female)\n",
    "    3. Job (numeric: 0 - unskilled and non-resident, 1 - unskilled and resident, 2 - skilled, 3 - highly skilled)\n",
    "    4. Housing (text: own, rent, or free)\n",
    "    5. Saving accounts (text - little, moderate, quite rich, rich)\n",
    "    6. Checking account (numeric, in DM - Deutsch Mark)\n",
    "    7. Credit amount (numeric, in DM)\n",
    "    8. Duration (numeric, in month)\n",
    "    9. Purpose (text: car, furniture/equipment, radio/TV, domestic appliances, repairs, education, business, vacation/others)\n",
    "    10. Risk (text: good,bad)''',\"name\":\"German Credit Data\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_9={\"metadata\":'''\"This dataset is from a 2014 survey that measures attitudes towards mental health and frequency of mental health disorders in the tech workplace.\"\n",
    "\n",
    "Figure the essential parameters affecting mental health and its acceptance\n",
    "Timestamp - Time the survey was submitted\n",
    "Age - Respondent age\n",
    "Gender - Respondent gender\n",
    "Country - Respondent country\n",
    "state - If you live in the United States, which state or territory do you live in?\n",
    "self_employed - Are you self-employed?\n",
    "family_history - Do you have a family history of mental illness?\n",
    "treatment - Have you sought treatment for a mental health condition?\n",
    "work_interfere - If you have a mental health condition, do you feel that it interferes with your work?\n",
    "no_employees - How many employees does your company or organization have?\n",
    "remote_work - Do you work remotely (outside of an office) at least 50% of the time?\n",
    "tech_company - Is your employer primarily a tech company/organization?\n",
    "benefits - Does your employer provide mental health benefits?\n",
    "care_options - Do you know the options for mental health care your employer provides?\n",
    "wellness_program - Has your employer ever discussed mental health as part of an employee wellness program?\n",
    "seek_help - Does your employer provide resources to learn more about mental health issues and how to seek help?\n",
    "anonymity - Is your anonymity protected if you choose to take advantage of mental health or substance abuse treatment resources?\n",
    "leave - How easy is it for you to take medical leave for a mental health condition?\n",
    "mental_health_consequence - Do you think that discussing a mental health issue with your employer would have negative consequences?\n",
    "phys_health_consequence - Do you think that discussing a physical health issue with your employer would have negative consequences?\n",
    "coworkers - Would you be willing to discuss a mental health issue with your coworkers?\n",
    "supervisor - Would you be willing to discuss a mental health issue with your direct supervisor(s)?\n",
    "mental_health_interview - Would you bring up a mental health issue with a potential employer in an interview?\n",
    "phys_health_interview - Would you bring up a physical health issue with a potential employer in an interview?\n",
    "mental_vs_physical - Do you feel that your employer takes mental health as seriously as physical health?\n",
    "obs_consequence - Have you heard of or observed negative consequences for coworkers with mental health conditions in your workplace?\n",
    "comments - Any additional notes or comments''',\"name\":\"mental_health\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_10={\"metadata\":'''A food confectionary is undergoing a tough time in sales and wants use machine learning to turn their fortunes around. They have captured their daily transaction data from 30th Oct 2016 to 9th Apr 2017 and want to understand what are all the food bundles that are popular among their customers. \n",
    "\n",
    "Your job is to perform <b>Market Basket Analysis</b> using the Apriori algorithm and recommend the confectionary the food bundles that they should be marketing more. ''',\"name\":\"food_dataset\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_11 = {\"metadata\":'''**Problem:**The dataset is from a bank, using which we have to predict whether the subject subscribes to a term deposit or not.<br/>\n",
    "\n",
    "**Attributes:**\n",
    "The dataset has the following attributes:<br/>\n",
    "1  - age (numeric)<br/>\n",
    "2  - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n",
    "                                    \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\"). <br/>\n",
    "3  - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)<br/>\n",
    "4  - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")<br/>\n",
    "5  - default: has credit in default? (binary: \"yes\",\"no\")<br/>\n",
    "6  - balance: average yearly balance, in euros (numeric) <br/>\n",
    "7  - housing: has housing loan? (binary: \"yes\",\"no\")<br/>\n",
    "8  - loan: has personal loan? (binary: \"yes\",\"no\")<br/>\n",
    "9  - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") <br/>\n",
    "10 - day: last contact day of the month (numeric)<br/>\n",
    "11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")<br/>\n",
    "12 - duration: last contact duration, in seconds (numeric)<br/>\n",
    "13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)<br/>\n",
    "14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client      was not previously contacted)<br/>  \n",
    "15 - previous: number of contacts performed before this campaign and for this client (numeric)<br/>\n",
    "16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")<br/>\n",
    "**Response Variable (desired target):**<br/>\n",
    "17 - y - has the client subscribed to a __term deposit?__ (binary: \"yes\",\"no\")''',\"name\":\"bank_deposit\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_12={\"metadata\":'''The dataset consists of 10000 individuals and whether their credit card has defaulted or not. \n",
    "\n",
    "**Objective :**  \n",
    "\n",
    "Predict whether the individual will default in their credit card payment.\n",
    "\n",
    "Below are the column description:\n",
    "- **default** : Whether the individual has defaulted\n",
    "- **student** : Whether the individual is student\n",
    "- **balance** : The average balance that the customer has remaining on their credit card after making their monthly payment\n",
    "- **income** : Income of individual''',\"name\":\"credit_default\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_13={\"metadata\":'''Mining companies face problems regarding the impurities present in Ore. More the impurities poorer the ore. \n",
    "In this problem we have to classify the **Grade** (quality) of Iron ore at the end process based on Silica present. <br/> \n",
    "Grade 1- Supreme Quality<br/>\n",
    "Grade 2- Good Quality<br/>\n",
    "Grade 3- Average Quality<br/>\n",
    "Grade 4- Poor Quality''',\"name\":\"mining_data\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_14={\"metadata\":'''This dataset contains properties sold in New York City over a 12-month period from September 2016 to September 2017. The objective is to build a model to predict sale value in the future.''',\"name\":\"nyc_data\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_15={\"metadata\":'''Goal of this project is to **predict the sales** of a Retail outlet based on the historical data provided for sales.**Item Identifier**: A code provided for the item of sale <br>\n",
    "**Item Weight**: Weight of item <br>\n",
    "**Item Fat Content**: A categorical column of how much fat is present in the item : ‘Low Fat’, ‘Regular’, ‘low fat’, ‘LF’, ‘reg’ <br>\n",
    "**Item Visibility**: Numeric value for how visible the item is  <br> \n",
    "**Item Type**: What category does the item belong to: ‘Dairy’, ‘Soft Drinks’, ‘Meat’, ‘Fruits and Vegetables’, ‘Household’, ‘Baking Goods’, ‘Snack Foods’, ‘Frozen Foods’, ‘Breakfast’, ’Health and Hygiene’, ‘Hard Drinks’, ‘Canned’, ‘Breads’, ‘Starchy Foods’, ‘Others’, ‘Seafood’. <br>\n",
    "**Item MRP**: The MRP price of item <br>\n",
    "**Outlet Identifier**: Which outlet was the item sold. This will be categorical column <br>\n",
    "**Outlet Establishment Year**: Which year was the outlet established <br>\n",
    "**Outlet Size**: A categorical column to explain size of outlet: ‘Medium’, ‘High’, ‘Small’.  <br> \n",
    "**Outlet Location Type**: A categorical column to describe the location of the outlet: ‘Tier 1’, ‘Tier 2’, ‘Tier 3’  <br>\n",
    "**Outlet Type** : Categorical column for type of outlet: ‘Supermarket Type1’, ‘Supermarket Type2’, ‘Supermarket Type3’, ‘Grocery Store’  <br>\n",
    "**Item Outlet Sales**: The amount of sales for an item.  <br> \n",
    "**Source**: Whether the data is from train or test.  <br>''',\"name\":\"sales_prediction\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_16={\"metadata\":'''Due to prevalent fraud in finance domain, it is imperative for credit card companies to be able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n",
    "The datasets contains transactions made by credit cards in September 2013 by European cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions.Classify fraudulent transaction from non fraudulent transactions using machine learning algorithms.''',\"name\":\"financial_fraud\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_17={\"metadata\":'''The dataset gives you information about a marketing campaign of a financial institution in which you will have to analyze in order to find ways to look for future strategies in order to improve future marketing campaigns for the bank.The data set is imbalanced with 4521 instances and 17 columns.1 - age (numeric)\n",
    "\n",
    "2 - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n",
    "                                    \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\") \n",
    "\n",
    "3 - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
    "\n",
    "4 - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n",
    "\n",
    "5 - default: has credit in default? (binary: \"yes\",\"no\")\n",
    "\n",
    "6 - balance: average yearly balance, in euros (numeric) \n",
    "\n",
    "7 - housing: has housing loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "8 - loan: has personal loan? (binary: \"yes\",\"no\")\n",
    "\n",
    "9 - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \n",
    "\n",
    "10 - day: last contact day of the month (numeric)\n",
    "\n",
    "11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n",
    "\n",
    "12 - duration: last contact duration, in seconds (numeric)\n",
    "\n",
    "13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "\n",
    "14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n",
    "  \n",
    "15 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "\n",
    "16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n",
    "\n",
    " Response Variable (desired target):__\n",
    "\n",
    "17 - y - has the client subscribed to a __term deposit?__ (binary: \"yes\",\"no\")''',\"name\":\"fa_marketing\",\"url\":\"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "final_df=pd.DataFrame([dataset_1,dataset_2,dataset_3,dataset_4,dataset_5,dataset_6,dataset_7,dataset_8,dataset_9,dataset_10,dataset_11,dataset_12,dataset_13,dataset_14,dataset_15,dataset_16,dataset_17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new=[{\"metadata\":\"This is a financial dataset\",\"name\":\"Finance\",\"url\":\"https://bakshi.com\"}]\n",
    "dataset_new=pd.DataFrame(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a financial dataset</td>\n",
       "      <td>Finance</td>\n",
       "      <td>https://bakshi.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      metadata     name                 url\n",
       "0  This is a financial dataset  Finance  https://bakshi.com"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Context Machine Learning with R by Brett Lantz...</td>\n",
       "      <td>Medical Cost Personal Datasets</td>\n",
       "      <td>https://www.kaggle.com/mirichoi0218/insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McCarran International Airport in Las Vegas is...</td>\n",
       "      <td>Airport Dataset</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An Institute of Management Studies was establi...</td>\n",
       "      <td>placement_data</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We have a dataset of students in a university....</td>\n",
       "      <td>university_data</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*__Airbnb__* is an American online vacation-pl...</td>\n",
       "      <td>airbnb</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kerala is one of the worst flood-hit states in...</td>\n",
       "      <td>kerala_floods</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dataset from Davide Chicco, Giuseppe Jurman: â...</td>\n",
       "      <td>heart_survival</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The original dataset contains 1000 entries wit...</td>\n",
       "      <td>German Credit Data</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"This dataset is from a 2014 survey that measu...</td>\n",
       "      <td>mental_health</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A food confectionary is undergoing a tough tim...</td>\n",
       "      <td>food_dataset</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>**Problem:**The dataset is from a bank, using ...</td>\n",
       "      <td>bank_deposit</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The dataset consists of 10000 individuals and ...</td>\n",
       "      <td>credit_default</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mining companies face problems regarding the i...</td>\n",
       "      <td>mining_data</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This dataset contains properties sold in New Y...</td>\n",
       "      <td>nyc_data</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Goal of this project is to **predict the sales...</td>\n",
       "      <td>sales_prediction</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Due to prevalent fraud in finance domain, it i...</td>\n",
       "      <td>financial_fraud</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The dataset gives you information about a mark...</td>\n",
       "      <td>fa_marketing</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>This is a financial dataset</td>\n",
       "      <td>Finance</td>\n",
       "      <td>https://bakshi.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             metadata  \\\n",
       "0   Context Machine Learning with R by Brett Lantz...   \n",
       "1   McCarran International Airport in Las Vegas is...   \n",
       "2   An Institute of Management Studies was establi...   \n",
       "3   We have a dataset of students in a university....   \n",
       "4   *__Airbnb__* is an American online vacation-pl...   \n",
       "5   Kerala is one of the worst flood-hit states in...   \n",
       "6   Dataset from Davide Chicco, Giuseppe Jurman: â...   \n",
       "7   The original dataset contains 1000 entries wit...   \n",
       "8   \"This dataset is from a 2014 survey that measu...   \n",
       "9   A food confectionary is undergoing a tough tim...   \n",
       "10  **Problem:**The dataset is from a bank, using ...   \n",
       "11  The dataset consists of 10000 individuals and ...   \n",
       "12  Mining companies face problems regarding the i...   \n",
       "13  This dataset contains properties sold in New Y...   \n",
       "14  Goal of this project is to **predict the sales...   \n",
       "15  Due to prevalent fraud in finance domain, it i...   \n",
       "16  The dataset gives you information about a mark...   \n",
       "17                        This is a financial dataset   \n",
       "\n",
       "                              name  \\\n",
       "0   Medical Cost Personal Datasets   \n",
       "1                  Airport Dataset   \n",
       "2                   placement_data   \n",
       "3                  university_data   \n",
       "4                           airbnb   \n",
       "5                    kerala_floods   \n",
       "6                   heart_survival   \n",
       "7               German Credit Data   \n",
       "8                    mental_health   \n",
       "9                     food_dataset   \n",
       "10                    bank_deposit   \n",
       "11                  credit_default   \n",
       "12                     mining_data   \n",
       "13                        nyc_data   \n",
       "14                sales_prediction   \n",
       "15                 financial_fraud   \n",
       "16                    fa_marketing   \n",
       "17                         Finance   \n",
       "\n",
       "                                              url  \n",
       "0   https://www.kaggle.com/mirichoi0218/insurance  \n",
       "1                                              NA  \n",
       "2                                              NA  \n",
       "3                                              NA  \n",
       "4                                              NA  \n",
       "5                                              NA  \n",
       "6                                              NA  \n",
       "7                                              NA  \n",
       "8                                              NA  \n",
       "9                                              NA  \n",
       "10                                             NA  \n",
       "11                                             NA  \n",
       "12                                             NA  \n",
       "13                                             NA  \n",
       "14                                             NA  \n",
       "15                                             NA  \n",
       "16                                             NA  \n",
       "17                             https://bakshi.com  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.append(dataset_new,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Context Machine Learning with R by Brett Lantz...</td>\n",
       "      <td>Medical Cost Personal Datasets</td>\n",
       "      <td>https://www.kaggle.com/mirichoi0218/insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McCarran International Airport in Las Vegas is...</td>\n",
       "      <td>Airport Dataset</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An Institute of Management Studies was establi...</td>\n",
       "      <td>placement_data</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We have a dataset of students in a university....</td>\n",
       "      <td>university_data</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>*__Airbnb__* is an American online vacation-pl...</td>\n",
       "      <td>airbnb</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kerala is one of the worst flood-hit states in...</td>\n",
       "      <td>kerala_floods</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dataset from Davide Chicco, Giuseppe Jurman: â...</td>\n",
       "      <td>heart_survival</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The original dataset contains 1000 entries wit...</td>\n",
       "      <td>German Credit Data</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"This dataset is from a 2014 survey that measu...</td>\n",
       "      <td>mental_health</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A food confectionary is undergoing a tough tim...</td>\n",
       "      <td>food_dataset</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>**Problem:**The dataset is from a bank, using ...</td>\n",
       "      <td>bank_deposit</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The dataset consists of 10000 individuals and ...</td>\n",
       "      <td>credit_default</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mining companies face problems regarding the i...</td>\n",
       "      <td>mining_data</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This dataset contains properties sold in New Y...</td>\n",
       "      <td>nyc_data</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Goal of this project is to **predict the sales...</td>\n",
       "      <td>sales_prediction</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Due to prevalent fraud in finance domain, it i...</td>\n",
       "      <td>financial_fraud</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The dataset gives you information about a mark...</td>\n",
       "      <td>fa_marketing</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             metadata  \\\n",
       "0   Context Machine Learning with R by Brett Lantz...   \n",
       "1   McCarran International Airport in Las Vegas is...   \n",
       "2   An Institute of Management Studies was establi...   \n",
       "3   We have a dataset of students in a university....   \n",
       "4   *__Airbnb__* is an American online vacation-pl...   \n",
       "5   Kerala is one of the worst flood-hit states in...   \n",
       "6   Dataset from Davide Chicco, Giuseppe Jurman: â...   \n",
       "7   The original dataset contains 1000 entries wit...   \n",
       "8   \"This dataset is from a 2014 survey that measu...   \n",
       "9   A food confectionary is undergoing a tough tim...   \n",
       "10  **Problem:**The dataset is from a bank, using ...   \n",
       "11  The dataset consists of 10000 individuals and ...   \n",
       "12  Mining companies face problems regarding the i...   \n",
       "13  This dataset contains properties sold in New Y...   \n",
       "14  Goal of this project is to **predict the sales...   \n",
       "15  Due to prevalent fraud in finance domain, it i...   \n",
       "16  The dataset gives you information about a mark...   \n",
       "\n",
       "                              name  \\\n",
       "0   Medical Cost Personal Datasets   \n",
       "1                  Airport Dataset   \n",
       "2                   placement_data   \n",
       "3                  university_data   \n",
       "4                           airbnb   \n",
       "5                    kerala_floods   \n",
       "6                   heart_survival   \n",
       "7               German Credit Data   \n",
       "8                    mental_health   \n",
       "9                     food_dataset   \n",
       "10                    bank_deposit   \n",
       "11                  credit_default   \n",
       "12                     mining_data   \n",
       "13                        nyc_data   \n",
       "14                sales_prediction   \n",
       "15                 financial_fraud   \n",
       "16                    fa_marketing   \n",
       "\n",
       "                                              url  \n",
       "0   https://www.kaggle.com/mirichoi0218/insurance  \n",
       "1                                              NA  \n",
       "2                                              NA  \n",
       "3                                              NA  \n",
       "4                                              NA  \n",
       "5                                              NA  \n",
       "6                                              NA  \n",
       "7                                              NA  \n",
       "8                                              NA  \n",
       "9                                              NA  \n",
       "10                                             NA  \n",
       "11                                             NA  \n",
       "12                                             NA  \n",
       "13                                             NA  \n",
       "14                                             NA  \n",
       "15                                             NA  \n",
       "16                                             NA  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from flask import Flask, render_template, session, request,send_from_directory,redirect,url_for,request\n",
    "from oauth2client.contrib.flask_util import UserOAuth2\n",
    "from flask_pymongo import PyMongo\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#df_data = pd.read_csv(\"NewQuip.csv\")\n",
    "df_desc = final_df['metadata']\n",
    "# Instantiate a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "# It fits the data and transform it as a vector\n",
    "X = vectorizer.fit_transform(df_desc)\n",
    "# Convert the X as transposed matrix\n",
    "X = X.T.toarray()\n",
    "# Create a DataFrame and set the vocabulary as the index\n",
    "df = pd.DataFrame(X, index=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034055</td>\n",
       "      <td>0.122564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098511</td>\n",
       "      <td>0.047611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10th</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036754</td>\n",
       "      <td>0.132281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>york</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>0.117068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312625</td>\n",
       "      <td>0.104418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>œmachine</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>796 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0    1         2         3    4         5         6   \\\n",
       "10        0.000000  0.0  0.034055  0.122564  0.0  0.000000  0.098511   \n",
       "1000      0.000000  0.0  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "10000     0.000000  0.0  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "10th      0.000000  0.0  0.167985  0.000000  0.0  0.000000  0.000000   \n",
       "11        0.000000  0.0  0.036754  0.132281  0.0  0.000000  0.106321   \n",
       "...            ...  ...       ...       ...  ...       ...       ...   \n",
       "yes       0.000000  0.0  0.039948  0.000000  0.0  0.055764  0.000000   \n",
       "york      0.000000  0.0  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "you       0.117068  0.0  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "your      0.000000  0.0  0.000000  0.000000  0.0  0.000000  0.000000   \n",
       "œmachine  0.000000  0.0  0.000000  0.000000  0.0  0.000000  0.161979   \n",
       "\n",
       "                7         8         9         10        11   12        13  \\\n",
       "10        0.047611  0.000000  0.000000  0.026075  0.000000  0.0  0.000000   \n",
       "1000      0.078285  0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "10000     0.000000  0.000000  0.000000  0.000000  0.108597  0.0  0.000000   \n",
       "10th      0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "11        0.000000  0.000000  0.000000  0.028142  0.000000  0.0  0.000000   \n",
       "...            ...       ...       ...       ...       ...  ...       ...   \n",
       "yes       0.000000  0.000000  0.000000  0.122347  0.000000  0.0  0.000000   \n",
       "york      0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.221812   \n",
       "you       0.000000  0.380556  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "your      0.000000  0.312625  0.104418  0.000000  0.000000  0.0  0.000000   \n",
       "œmachine  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "\n",
       "           14   15        16  \n",
       "10        0.0  0.0  0.032097  \n",
       "1000      0.0  0.0  0.000000  \n",
       "10000     0.0  0.0  0.000000  \n",
       "10th      0.0  0.0  0.000000  \n",
       "11        0.0  0.0  0.034642  \n",
       "...       ...  ...       ...  \n",
       "yes       0.0  0.0  0.150605  \n",
       "york      0.0  0.0  0.000000  \n",
       "you       0.0  0.0  0.082669  \n",
       "your      0.0  0.0  0.000000  \n",
       "œmachine  0.0  0.0  0.000000  \n",
       "\n",
       "[796 rows x 17 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_articles(q, df):\n",
    "  video_list = []\n",
    "  print(\"query:\", q)\n",
    "  # Convert the query become a vector\n",
    "  q = [q]\n",
    "  q_vec = vectorizer.transform(q).toarray().reshape(df.shape[0],)\n",
    "  sim = {}\n",
    "  # Calculate the similarity\n",
    "  for i in range(10):\n",
    "    sim[i] = np.dot(df.loc[:, i].values, q_vec) / np.linalg.norm(df.loc[:, i]) * np.linalg.norm(q_vec)\n",
    "  \n",
    "  # Sort the values \n",
    "  sim_sorted = sorted(sim.items(), key=lambda x: x[1], reverse=True)\n",
    "  # Print the articles and their similarity values\n",
    "  for k, v in sim_sorted:\n",
    "    if v != 0.0:\n",
    "      print(\"Cosine Similarities:\", v)\n",
    "      print (\"Recommendation\",k)\n",
    "      print(final_df.iloc[k]['name'])\n",
    "      video_desc = final_df.iloc[k]['name']\n",
    "      video_list = video_list + [video_desc]\n",
    "      print()\n",
    "  return video_list\n",
    "# Add The Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: According to Epsilon research, 80% of customers are more likely to do business with you if you provide personalized service. Banking is no exception.\n",
      "\n",
      "The digitalization of everyday lives means that customers expect services to be delivered in a personalized and timely manner… and often before they´ve even realized they need the service. In their 3rd Kaggle competition, Santander Group aims to go a step beyond recognizing that there is a need to provide a customer a financial service and intends to determine the amount or value of the customer's transaction. This means anticipating customer needs in a more concrete, but also simple and personal way. With so many choices for financial services, this need is greater now than ever before.\n",
      "\n",
      "In this competition, Santander Group is asking Kagglers to help them identify the value of transactions for each potential customer. This is a first step that Santander needs to nail in order to personalize their services at scale.\n",
      "Cosine Similarities: 0.2854002603891628\n",
      "Recommendation 9\n",
      "food_dataset\n",
      "\n",
      "Cosine Similarities: 0.20664504328574487\n",
      "Recommendation 8\n",
      "mental_health\n",
      "\n",
      "Cosine Similarities: 0.2046520255886866\n",
      "Recommendation 4\n",
      "airbnb\n",
      "\n",
      "Cosine Similarities: 0.19588713466597163\n",
      "Recommendation 0\n",
      "Medical Cost Personal Datasets\n",
      "\n",
      "Cosine Similarities: 0.1939160956546029\n",
      "Recommendation 5\n",
      "kerala_floods\n",
      "\n",
      "Cosine Similarities: 0.18786029918311783\n",
      "Recommendation 1\n",
      "Airport Dataset\n",
      "\n",
      "Cosine Similarities: 0.18423465918004822\n",
      "Recommendation 2\n",
      "placement_data\n",
      "\n",
      "Cosine Similarities: 0.1830331239277642\n",
      "Recommendation 7\n",
      "German Credit Data\n",
      "\n",
      "Cosine Similarities: 0.06602914567793745\n",
      "Recommendation 6\n",
      "heart_survival\n",
      "\n",
      "Cosine Similarities: 0.029256617738166686\n",
      "Recommendation 3\n",
      "university_data\n",
      "\n",
      "['food_dataset', 'mental_health', 'airbnb', 'Medical Cost Personal Datasets', 'kerala_floods', 'Airport Dataset', 'placement_data', 'German Credit Data', 'heart_survival', 'university_data']\n"
     ]
    }
   ],
   "source": [
    "# Add The Query\n",
    "q1 = '''According to Epsilon research, 80% of customers are more likely to do business with you if you provide personalized service. Banking is no exception.\n",
    "\n",
    "The digitalization of everyday lives means that customers expect services to be delivered in a personalized and timely manner… and often before they´ve even realized they need the service. In their 3rd Kaggle competition, Santander Group aims to go a step beyond recognizing that there is a need to provide a customer a financial service and intends to determine the amount or value of the customer's transaction. This means anticipating customer needs in a more concrete, but also simple and personal way. With so many choices for financial services, this need is greater now than ever before.\n",
    "\n",
    "In this competition, Santander Group is asking Kagglers to help them identify the value of transactions for each potential customer. This is a first step that Santander needs to nail in order to personalize their services at scale.'''\n",
    "# Call the function\n",
    "output = get_similar_articles(q1, df)\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sk250164\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(doc_id,similarity_matrix,matrix):\n",
    "    print (f'Document: {final_df.iloc[doc_id][\"metadata\"]}')\n",
    "    print ('\\n')\n",
    "    print ('Similar Documents:')\n",
    "    if matrix=='Cosine Similarity':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])[::-1]\n",
    "    elif matrix=='Euclidean Distance':\n",
    "        similar_ix=np.argsort(similarity_matrix[doc_id])\n",
    "    for ix in similar_ix:\n",
    "        if ix==doc_id:\n",
    "            continue\n",
    "        print('\\n')\n",
    "        print (f'Document: {final_df.iloc[ix][\"name\"]}')\n",
    "        print (f'{matrix} : {similarity_matrix[doc_id][ix]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: **Problem:**The dataset is from a bank, using which we have to predict whether the subject subscribes to a term deposit or not.<br/>\n",
      "\n",
      "**Attributes:**\n",
      "The dataset has the following attributes:<br/>\n",
      "1  - age (numeric)<br/>\n",
      "2  - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n",
      "                                    \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\"). <br/>\n",
      "3  - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)<br/>\n",
      "4  - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")<br/>\n",
      "5  - default: has credit in default? (binary: \"yes\",\"no\")<br/>\n",
      "6  - balance: average yearly balance, in euros (numeric) <br/>\n",
      "7  - housing: has housing loan? (binary: \"yes\",\"no\")<br/>\n",
      "8  - loan: has personal loan? (binary: \"yes\",\"no\")<br/>\n",
      "9  - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") <br/>\n",
      "10 - day: last contact day of the month (numeric)<br/>\n",
      "11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")<br/>\n",
      "12 - duration: last contact duration, in seconds (numeric)<br/>\n",
      "13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)<br/>\n",
      "14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client      was not previously contacted)<br/>  \n",
      "15 - previous: number of contacts performed before this campaign and for this client (numeric)<br/>\n",
      "16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")<br/>\n",
      "**Response Variable (desired target):**<br/>\n",
      "17 - y - has the client subscribed to a __term deposit?__ (binary: \"yes\",\"no\")\n",
      "\n",
      "\n",
      "Similar Documents:\n",
      "\n",
      "\n",
      "Document: fa_marketing\n",
      "Cosine Similarity : 0.7462029827687895\n",
      "\n",
      "\n",
      "Document: credit_default\n",
      "Cosine Similarity : 0.5852024136136459\n",
      "\n",
      "\n",
      "Document: food_dataset\n",
      "Cosine Similarity : 0.5749779417343959\n",
      "\n",
      "\n",
      "Document: nyc_data\n",
      "Cosine Similarity : 0.4699259393459914\n",
      "\n",
      "\n",
      "Document: heart_survival\n",
      "Cosine Similarity : 0.4629531586649311\n",
      "\n",
      "\n",
      "Document: financial_fraud\n",
      "Cosine Similarity : 0.4627614130419615\n",
      "\n",
      "\n",
      "Document: mining_data\n",
      "Cosine Similarity : 0.4496193699048106\n",
      "\n",
      "\n",
      "Document: mental_health\n",
      "Cosine Similarity : 0.4243044727500621\n",
      "\n",
      "\n",
      "Document: kerala_floods\n",
      "Cosine Similarity : 0.41787794549307933\n",
      "\n",
      "\n",
      "Document: sales_prediction\n",
      "Cosine Similarity : 0.3873967325806628\n",
      "\n",
      "\n",
      "Document: German Credit Data\n",
      "Cosine Similarity : 0.3805021755605709\n",
      "\n",
      "\n",
      "Document: university_data\n",
      "Cosine Similarity : 0.33445324072379606\n",
      "\n",
      "\n",
      "Document: airbnb\n",
      "Cosine Similarity : 0.31181790942470067\n",
      "\n",
      "\n",
      "Document: Airport Dataset\n",
      "Cosine Similarity : 0.3006023957564002\n",
      "\n",
      "\n",
      "Document: placement_data\n",
      "Cosine Similarity : 0.2810925155158636\n",
      "\n",
      "\n",
      "Document: Medical Cost Personal Datasets\n",
      "Cosine Similarity : 0.27437249572826666\n",
      "Document: **Problem:**The dataset is from a bank, using which we have to predict whether the subject subscribes to a term deposit or not.<br/>\n",
      "\n",
      "**Attributes:**\n",
      "The dataset has the following attributes:<br/>\n",
      "1  - age (numeric)<br/>\n",
      "2  - job : type of job (categorical: \"admin.\",\"unknown\",\"unemployed\",\"management\",\"housemaid\",\"entrepreneur\",\"student\",\n",
      "                                    \"blue-collar\",\"self-employed\",\"retired\",\"technician\",\"services\"). <br/>\n",
      "3  - marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)<br/>\n",
      "4  - education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")<br/>\n",
      "5  - default: has credit in default? (binary: \"yes\",\"no\")<br/>\n",
      "6  - balance: average yearly balance, in euros (numeric) <br/>\n",
      "7  - housing: has housing loan? (binary: \"yes\",\"no\")<br/>\n",
      "8  - loan: has personal loan? (binary: \"yes\",\"no\")<br/>\n",
      "9  - contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") <br/>\n",
      "10 - day: last contact day of the month (numeric)<br/>\n",
      "11 - month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")<br/>\n",
      "12 - duration: last contact duration, in seconds (numeric)<br/>\n",
      "13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)<br/>\n",
      "14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client      was not previously contacted)<br/>  \n",
      "15 - previous: number of contacts performed before this campaign and for this client (numeric)<br/>\n",
      "16 - poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")<br/>\n",
      "**Response Variable (desired target):**<br/>\n",
      "17 - y - has the client subscribed to a __term deposit?__ (binary: \"yes\",\"no\")\n",
      "\n",
      "\n",
      "Similar Documents:\n",
      "\n",
      "\n",
      "Document: fa_marketing\n",
      "Euclidean Distance : 15.285989347848366\n",
      "\n",
      "\n",
      "Document: credit_default\n",
      "Euclidean Distance : 18.297343915847954\n",
      "\n",
      "\n",
      "Document: nyc_data\n",
      "Euclidean Distance : 18.466881669477523\n",
      "\n",
      "\n",
      "Document: food_dataset\n",
      "Euclidean Distance : 20.89033885302456\n",
      "\n",
      "\n",
      "Document: mining_data\n",
      "Euclidean Distance : 21.512749279492493\n",
      "\n",
      "\n",
      "Document: heart_survival\n",
      "Euclidean Distance : 21.82011927931503\n",
      "\n",
      "\n",
      "Document: university_data\n",
      "Euclidean Distance : 22.259719941921162\n",
      "\n",
      "\n",
      "Document: financial_fraud\n",
      "Euclidean Distance : 22.574040865899516\n",
      "\n",
      "\n",
      "Document: sales_prediction\n",
      "Euclidean Distance : 25.093652855839444\n",
      "\n",
      "\n",
      "Document: Airport Dataset\n",
      "Euclidean Distance : 25.698646957185844\n",
      "\n",
      "\n",
      "Document: kerala_floods\n",
      "Euclidean Distance : 25.906464183860898\n",
      "\n",
      "\n",
      "Document: mental_health\n",
      "Euclidean Distance : 26.12008478010657\n",
      "\n",
      "\n",
      "Document: airbnb\n",
      "Euclidean Distance : 27.320186915990657\n",
      "\n",
      "\n",
      "Document: German Credit Data\n",
      "Euclidean Distance : 29.35977121787327\n",
      "\n",
      "\n",
      "Document: placement_data\n",
      "Euclidean Distance : 32.316422549751024\n",
      "\n",
      "\n",
      "Document: Medical Cost Personal Datasets\n",
      "Euclidean Distance : 32.59260268150048\n"
     ]
    }
   ],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(doc), tags=[i]) for i, doc in enumerate(final_df.metadata)]\n",
    "model_d2v = Doc2Vec(vector_size=100,alpha=0.025, min_count=1)\n",
    "  \n",
    "model_d2v.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model_d2v.train(tagged_data,\n",
    "                total_examples=model_d2v.corpus_count,\n",
    "                epochs=model_d2v.epochs)\n",
    "    \n",
    "document_embeddings=np.zeros((final_df.shape[0],100))\n",
    "\n",
    "for i in range(len(document_embeddings)):\n",
    "    document_embeddings[i]=model_d2v.docvecs[i]\n",
    "    \n",
    "    \n",
    "pairwise_similarities=cosine_similarity(document_embeddings)\n",
    "pairwise_differences=euclidean_distances(document_embeddings)\n",
    "\n",
    "most_similar(10,pairwise_similarities,'Cosine Similarity')\n",
    "most_similar(10,pairwise_differences,'Euclidean Distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: Context Machine Learning with R by Brett Lantz is a book that provides an introduction to machine learning using R. As far as I can tell, Packt Publishing does not make its datasets available online unless you buy the book and create a user account which can be a problem if you are checking the book out from the library or borrowing the book from a friend. All of these datasets are in the public domain but simply needed some cleaning up and recoding to match the format in the book.\n",
      "\n",
      "age: age of primary beneficiary\n",
      "\n",
      "sex: insurance contractor gender, female, male\n",
      "\n",
      "bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
      "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
      "\n",
      "children: Number of children covered by health insurance / Number of dependents\n",
      "\n",
      "smoker: Smoking\n",
      "\n",
      "region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
      "\n",
      "charges: Individual medical costs billed by health insurance\n",
      "\n",
      "\n",
      "Similar Documents:\n",
      "\n",
      "\n",
      "Document: financial_fraud\n",
      "Cosine Similarity : 0.6872518062591553\n",
      "\n",
      "\n",
      "Document: food_dataset\n",
      "Cosine Similarity : 0.657721221446991\n",
      "\n",
      "\n",
      "Document: mental_health\n",
      "Cosine Similarity : 0.639443039894104\n",
      "\n",
      "\n",
      "Document: fa_marketing\n",
      "Cosine Similarity : 0.5867990255355835\n",
      "\n",
      "\n",
      "Document: German Credit Data\n",
      "Cosine Similarity : 0.5846432447433472\n",
      "\n",
      "\n",
      "Document: sales_prediction\n",
      "Cosine Similarity : 0.5768706202507019\n",
      "\n",
      "\n",
      "Document: placement_data\n",
      "Cosine Similarity : 0.5758187174797058\n",
      "\n",
      "\n",
      "Document: airbnb\n",
      "Cosine Similarity : 0.572365403175354\n",
      "\n",
      "\n",
      "Document: bank_deposit\n",
      "Cosine Similarity : 0.565448522567749\n",
      "\n",
      "\n",
      "Document: heart_survival\n",
      "Cosine Similarity : 0.5633351802825928\n",
      "\n",
      "\n",
      "Document: Airport Dataset\n",
      "Cosine Similarity : 0.5494237542152405\n",
      "\n",
      "\n",
      "Document: credit_default\n",
      "Cosine Similarity : 0.5467721223831177\n",
      "\n",
      "\n",
      "Document: university_data\n",
      "Cosine Similarity : 0.5371478199958801\n",
      "\n",
      "\n",
      "Document: mining_data\n",
      "Cosine Similarity : 0.5045785903930664\n",
      "\n",
      "\n",
      "Document: nyc_data\n",
      "Cosine Similarity : 0.35107773542404175\n",
      "\n",
      "\n",
      "Document: kerala_floods\n",
      "Cosine Similarity : 0.3340967297554016\n",
      "Document: Context Machine Learning with R by Brett Lantz is a book that provides an introduction to machine learning using R. As far as I can tell, Packt Publishing does not make its datasets available online unless you buy the book and create a user account which can be a problem if you are checking the book out from the library or borrowing the book from a friend. All of these datasets are in the public domain but simply needed some cleaning up and recoding to match the format in the book.\n",
      "\n",
      "age: age of primary beneficiary\n",
      "\n",
      "sex: insurance contractor gender, female, male\n",
      "\n",
      "bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height,\n",
      "objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9\n",
      "\n",
      "children: Number of children covered by health insurance / Number of dependents\n",
      "\n",
      "smoker: Smoking\n",
      "\n",
      "region: the beneficiary's residential area in the US, northeast, southeast, southwest, northwest.\n",
      "\n",
      "charges: Individual medical costs billed by health insurance\n",
      "\n",
      "\n",
      "Similar Documents:\n",
      "\n",
      "\n",
      "Document: financial_fraud\n",
      "Euclidean Distance : 11.290189743041992\n",
      "\n",
      "\n",
      "Document: mental_health\n",
      "Euclidean Distance : 12.043583869934082\n",
      "\n",
      "\n",
      "Document: food_dataset\n",
      "Euclidean Distance : 12.245893478393555\n",
      "\n",
      "\n",
      "Document: fa_marketing\n",
      "Euclidean Distance : 12.793675422668457\n",
      "\n",
      "\n",
      "Document: placement_data\n",
      "Euclidean Distance : 12.969881057739258\n",
      "\n",
      "\n",
      "Document: German Credit Data\n",
      "Euclidean Distance : 13.063386917114258\n",
      "\n",
      "\n",
      "Document: sales_prediction\n",
      "Euclidean Distance : 13.170446395874023\n",
      "\n",
      "\n",
      "Document: heart_survival\n",
      "Euclidean Distance : 13.232982635498047\n",
      "\n",
      "\n",
      "Document: bank_deposit\n",
      "Euclidean Distance : 13.299461364746094\n",
      "\n",
      "\n",
      "Document: university_data\n",
      "Euclidean Distance : 13.561766624450684\n",
      "\n",
      "\n",
      "Document: airbnb\n",
      "Euclidean Distance : 13.822100639343262\n",
      "\n",
      "\n",
      "Document: credit_default\n",
      "Euclidean Distance : 13.837657928466797\n",
      "\n",
      "\n",
      "Document: Airport Dataset\n",
      "Euclidean Distance : 14.001956939697266\n",
      "\n",
      "\n",
      "Document: mining_data\n",
      "Euclidean Distance : 14.745051383972168\n",
      "\n",
      "\n",
      "Document: kerala_floods\n",
      "Euclidean Distance : 17.121713638305664\n",
      "\n",
      "\n",
      "Document: nyc_data\n",
      "Euclidean Distance : 17.328874588012695\n"
     ]
    }
   ],
   "source": [
    "#from sentence_transformers import SentenceTransformer\n",
    "#sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "document_embeddings = sbert_model.encode(final_df['metadata'])\n",
    "\n",
    "pairwise_similarities=cosine_similarity(document_embeddings)\n",
    "pairwise_differences=euclidean_distances(document_embeddings)\n",
    "\n",
    "most_similar(0,pairwise_similarities,'Cosine Similarity')\n",
    "most_similar(0,pairwise_differences,'Euclidean Distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
